{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a61c6268-33de-4d7a-b0a8-dbc5d1b20147",
     "showTitle": true,
     "title": "Sample Data"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------+-------------+\n|FirstName|LastName |Country|State        |\n+---------+---------+-------+-------------+\n|Utsav    |Singh    |India  |Uttar Pradesh|\n|Sourav   |Goyal    |Dubai  |UAE          |\n|Akash    |Dua      |India  |Uttar Pradesh|\n|Manisha  |Sreepada |India  |Hyderabad    |\n|Vaishnavi|Choudhary|India  |Bengaluru    |\n+---------+---------+-------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "data = [(\"Utsav\",\"Singh\",\"India\",\"Uttar Pradesh\"),\n",
    "        (\"Sourav\",\"Goyal\",\"Dubai\",\"UAE\"),\n",
    "        (\"Akash\",\"Dua\",\"India\",\"Uttar Pradesh\"),\n",
    "        (\"Manisha\",\"Sreepada\",\"India\",\"Hyderabad\"),\n",
    "        (\"Vaishnavi\",\"Choudhary\",\"India\",\"Bengaluru\")]\n",
    "columns = [\"FirstName\",\"LastName\",\"Country\",\"State\"]\n",
    "df = spark.createDataFrame(data=data, schema=columns)\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d5b41f53-2067-4b55-8ee0-f85478f384a6",
     "showTitle": true,
     "title": "Select single & multiple column"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+\n|firstname| lastname|\n+---------+---------+\n|    Utsav|    Singh|\n|   Sourav|    Goyal|\n|    Akash|      Dua|\n|  Manisha| Sreepada|\n|Vaishnavi|Choudhary|\n+---------+---------+\n\n+---------+---------+\n|FirstName| LastName|\n+---------+---------+\n|    Utsav|    Singh|\n|   Sourav|    Goyal|\n|    Akash|      Dua|\n|  Manisha| Sreepada|\n|Vaishnavi|Choudhary|\n+---------+---------+\n\n+---------+---------+\n|firstname| lastname|\n+---------+---------+\n|    Utsav|    Singh|\n|   Sourav|    Goyal|\n|    Akash|      Dua|\n|  Manisha| Sreepada|\n|Vaishnavi|Choudhary|\n+---------+---------+\n\n+---------+---------+\n|firstname| lastname|\n+---------+---------+\n|    Utsav|    Singh|\n|   Sourav|    Goyal|\n|    Akash|      Dua|\n|  Manisha| Sreepada|\n|Vaishnavi|Choudhary|\n+---------+---------+\n\n+---------+---------+\n|FirstName| LastName|\n+---------+---------+\n|    Utsav|    Singh|\n|   Sourav|    Goyal|\n|    Akash|      Dua|\n|  Manisha| Sreepada|\n|Vaishnavi|Choudhary|\n+---------+---------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "df.select(\"firstname\",\"lastname\").show()\n",
    "df.select(df.FirstName,df.LastName).show()\n",
    "df.select(df[\"firstname\"],df[\"lastname\"]).show()\n",
    "\n",
    "#By using col() function\n",
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"firstname\"),col(\"lastname\")).show()\n",
    "\n",
    "#Select columns by regular expression\n",
    "df.select(df.colRegex(\"`^.*name*`\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "922c8858-aaf5-4196-9f61-2964fe927eaa",
     "showTitle": true,
     "title": "Select all columns"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------+-------------+\n|FirstName| LastName|Country|        State|\n+---------+---------+-------+-------------+\n|    Utsav|    Singh|  India|Uttar Pradesh|\n|   Sourav|    Goyal|  Dubai|          UAE|\n|    Akash|      Dua|  India|Uttar Pradesh|\n|  Manisha| Sreepada|  India|    Hyderabad|\n|Vaishnavi|Choudhary|  India|    Bengaluru|\n+---------+---------+-------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "df.select(\"*\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f855cbb-4116-49df-9308-b470b42d66c7",
     "showTitle": true,
     "title": "Select Columns by Index"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n|Country|        State|\n+-------+-------------+\n|  India|Uttar Pradesh|\n|  Dubai|          UAE|\n|  India|Uttar Pradesh|\n+-------+-------------+\nonly showing top 3 rows\n\n"
     ]
    }
   ],
   "source": [
    "df.select(df.columns[2:4]).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6028be33-34e7-4bb5-b031-18ea67858662",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- state: string (nullable = true)\n |-- gender: string (nullable = true)\n\n+----------------------+-----+------+\n|name                  |state|gender|\n+----------------------+-----+------+\n|{James, null, Smith}  |OH   |M     |\n|{Anna, Rose, }        |NY   |F     |\n|{Julia, , Williams}   |OH   |F     |\n|{Maria, Anne, Jones}  |NY   |M     |\n|{Jen, Mary, Brown}    |NY   |M     |\n|{Mike, Mary, Williams}|OH   |M     |\n+----------------------+-----+------+\n\n"
     ]
    }
   ],
   "source": [
    "data = [\n",
    "        ((\"James\",None,\"Smith\"),\"OH\",\"M\"),\n",
    "        ((\"Anna\",\"Rose\",\"\"),\"NY\",\"F\"),\n",
    "        ((\"Julia\",\"\",\"Williams\"),\"OH\",\"F\"),\n",
    "        ((\"Maria\",\"Anne\",\"Jones\"),\"NY\",\"M\"),\n",
    "        ((\"Jen\",\"Mary\",\"Brown\"),\"NY\",\"M\"),\n",
    "        ((\"Mike\",\"Mary\",\"Williams\"),\"OH\",\"M\")\n",
    "        ]\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField, StringType        \n",
    "schema = StructType([\n",
    "    StructField('name', StructType([\n",
    "         StructField('firstname', StringType(), True),\n",
    "         StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "         ])),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    "     ])\n",
    "df2 = spark.createDataFrame(data = data, schema = schema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False) # shows all columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d21c084-d440-4cae-b311-bb5eaf13366b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+--------+\n|firstname|middlename|lastname|\n+---------+----------+--------+\n|James    |null      |Smith   |\n|Anna     |Rose      |        |\n|Julia    |          |Williams|\n|Maria    |Anne      |Jones   |\n|Jen      |Mary      |Brown   |\n|Mike     |Mary      |Williams|\n+---------+----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"name.*\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c671551a-de3f-4414-9191-2b53f5e01490",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n|name                  |\n+----------------------+\n|{James, null, Smith}  |\n|{Anna, Rose, }        |\n|{Julia, , Williams}   |\n|{Maria, Anne, Jones}  |\n|{Jen, Mary, Brown}    |\n|{Mike, Mary, Williams}|\n+----------------------+\n\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"name\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0048f1fb-210b-4469-b634-da3f93d459d5",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|James    |Smith   |\n|Anna     |        |\n|Julia    |Williams|\n|Maria    |Jones   |\n|Jen      |Brown   |\n|Mike     |Williams|\n+---------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "df2.select(\"name.firstname\",\"name.lastname\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c65922b3-1455-4b30-9260-0f6d22f14412",
     "showTitle": true,
     "title": "Another Example"
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------+-------+-----+\n|firstname|lastname|country|state|\n+---------+--------+-------+-----+\n|James    |Smith   |USA    |CA   |\n|Michael  |Rose    |USA    |NY   |\n|Robert   |Williams|USA    |CA   |\n|Maria    |Jones   |USA    |FL   |\n+---------+--------+-------+-----+\n\n+---------+\n|firstname|\n+---------+\n|    James|\n|  Michael|\n|   Robert|\n|    Maria|\n+---------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|    James|   Smith|\n|  Michael|    Rose|\n|   Robert|Williams|\n|    Maria|   Jones|\n+---------+--------+\n\nroot\n |-- name: struct (nullable = true)\n |    |-- firstname: string (nullable = true)\n |    |-- middlename: string (nullable = true)\n |    |-- lastname: string (nullable = true)\n |-- state: string (nullable = true)\n |-- gender: string (nullable = true)\n\n+----------------------+-----+------+\n|name                  |state|gender|\n+----------------------+-----+------+\n|{James, null, Smith}  |OH   |M     |\n|{Anna, Rose, }        |NY   |F     |\n|{Julia, , Williams}   |OH   |F     |\n|{Maria, Anne, Jones}  |NY   |M     |\n|{Jen, Mary, Brown}    |NY   |M     |\n|{Mike, Mary, Williams}|OH   |M     |\n+----------------------+-----+------+\n\n+----------------------+\n|name                  |\n+----------------------+\n|{James, null, Smith}  |\n|{Anna, Rose, }        |\n|{Julia, , Williams}   |\n|{Maria, Anne, Jones}  |\n|{Jen, Mary, Brown}    |\n|{Mike, Mary, Williams}|\n+----------------------+\n\n+---------+--------+\n|firstname|lastname|\n+---------+--------+\n|James    |Smith   |\n|Anna     |        |\n|Julia    |Williams|\n|Maria    |Jones   |\n|Jen      |Brown   |\n|Mike     |Williams|\n+---------+--------+\n\n+---------+----------+--------+\n|firstname|middlename|lastname|\n+---------+----------+--------+\n|James    |null      |Smith   |\n|Anna     |Rose      |        |\n|Julia    |          |Williams|\n|Maria    |Anne      |Jones   |\n|Jen      |Mary      |Brown   |\n|Mike     |Mary      |Williams|\n+---------+----------+--------+\n\n"
     ]
    }
   ],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.appName('SparkByExamples.com').getOrCreate()\n",
    "\n",
    "data = [(\"James\",\"Smith\",\"USA\",\"CA\"),\n",
    "    (\"Michael\",\"Rose\",\"USA\",\"NY\"),\n",
    "    (\"Robert\",\"Williams\",\"USA\",\"CA\"),\n",
    "    (\"Maria\",\"Jones\",\"USA\",\"FL\")\n",
    "  ]\n",
    "\n",
    "columns = [\"firstname\",\"lastname\",\"country\",\"state\"]\n",
    "df = spark.createDataFrame(data = data, schema = columns)\n",
    "df.show(truncate=False)\n",
    "\n",
    "df.select(\"firstname\").show()\n",
    "\n",
    "df.select(\"firstname\",\"lastname\").show()\n",
    "\n",
    "#Using Dataframe object name\n",
    "df.select(df.firstname,df.lastname).show()\n",
    "\n",
    "# Using col function\n",
    "from pyspark.sql.functions import col\n",
    "df.select(col(\"firstname\"),col(\"lastname\")).show()\n",
    "\n",
    "data = [((\"James\",None,\"Smith\"),\"OH\",\"M\"),\n",
    "        ((\"Anna\",\"Rose\",\"\"),\"NY\",\"F\"),\n",
    "        ((\"Julia\",\"\",\"Williams\"),\"OH\",\"F\"),\n",
    "        ((\"Maria\",\"Anne\",\"Jones\"),\"NY\",\"M\"),\n",
    "        ((\"Jen\",\"Mary\",\"Brown\"),\"NY\",\"M\"),\n",
    "        ((\"Mike\",\"Mary\",\"Williams\"),\"OH\",\"M\")\n",
    "        ]\n",
    "\n",
    "from pyspark.sql.types import StructType,StructField, StringType        \n",
    "schema = StructType([\n",
    "    StructField('name', StructType([\n",
    "         StructField('firstname', StringType(), True),\n",
    "         StructField('middlename', StringType(), True),\n",
    "         StructField('lastname', StringType(), True)\n",
    "         ])),\n",
    "     StructField('state', StringType(), True),\n",
    "     StructField('gender', StringType(), True)\n",
    "     ])\n",
    "\n",
    "df2 = spark.createDataFrame(data = data, schema = schema)\n",
    "df2.printSchema()\n",
    "df2.show(truncate=False) # shows all columns\n",
    "\n",
    "df2.select(\"name\").show(truncate=False)\n",
    "df2.select(\"name.firstname\",\"name.lastname\").show(truncate=False)\n",
    "df2.select(\"name.*\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b4846d07-d68f-4c0c-a021-6f4ac435212c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day-4 Select",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
