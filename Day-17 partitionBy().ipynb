{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "09cc620e-46fb-47de-95fe-060e8d43ea92",
     "showTitle": true,
     "title": "Read CSV"
    }
   },
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"dbfs:/FileStore/shared_uploads/utsavsingh62@gmail.com/small_zipcode.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3eb7b691-d58f-4579-909c-8a448b5a35c4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+--------+-------------------+-----+----------+\n| id|zipcode|    type|               city|state|population|\n+---+-------+--------+-------------------+-----+----------+\n|  1|    704|STANDARD|               null|   PR|     30100|\n|  2|    704|    null|PASEO COSTA DEL SUR|   PR|      null|\n|  3|    709|    null|       BDA SAN LUIS|   PR|      3700|\n|  4|  76166|  UNIQUE|  CINGULAR WIRELESS|   TX|     84000|\n|  5|  76177|STANDARD|               null|   TX|      null|\n+---+-------+--------+-------------------+-----+----------+\n\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3547c2a3-d59e-4b8a-9f9b-fd2479383b1b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Out[7]: <pyspark.sql.readwriter.DataFrameWriter at 0x7f3299fe5970>"
     ]
    }
   ],
   "source": [
    "# partitionBy() Example\n",
    "df.write.option(\"header\",True).partitionBy(\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "55374407-3449-48f4-9175-9cad37a2f208",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#partitionBy() multiple columns\n",
    "df.write.option(\"header\",True).partitionBy(\"state\",\"city\").mode(\"overwrite\").csv(\"/tmp/zipcodes-state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08941235-8b4f-4dc5-a77b-a748335d9bea",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Initialize Spark session\n",
    "spark = SparkSession.builder.appName(\"partitioning_example\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3d768807-2c49-45e6-971f-3c1afc870f24",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-----+\n|   name|age|state|\n+-------+---+-----+\n|  Alice| 30|   CA|\n|    Bob| 45|   CA|\n|Charlie| 35|   NY|\n|  David| 40|   NY|\n|    Eve| 29|   TX|\n|  Frank| 50|   TX|\n+-------+---+-----+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row\n",
    "\n",
    "# Sample data\n",
    "data = [\n",
    "    Row(name=\"Alice\", age=30, state=\"CA\"),\n",
    "    Row(name=\"Bob\", age=45, state=\"CA\"),\n",
    "    Row(name=\"Charlie\", age=35, state=\"NY\"),\n",
    "    Row(name=\"David\", age=40, state=\"NY\"),\n",
    "    Row(name=\"Eve\", age=29, state=\"TX\"),\n",
    "    Row(name=\"Frank\", age=50, state=\"TX\")\n",
    "]\n",
    "\n",
    "# Create DataFrame\n",
    "df = spark.createDataFrame(data)\n",
    "df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a182f3c0-7428-4d60-ab95-5ca7a743aa8d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Output path\n",
    "output_path = \"dbfs:/tmp/people_partitioned_by_state\"\n",
    "\n",
    "# Write DataFrame partitioned by 'state'\n",
    "df.write.option(\"header\", \"true\").partitionBy(\"state\").mode(\"overwrite\").csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b9a1e043-e798-4583-88ae-1eb8b2756975",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+---+-----+\n|   name|age|state|\n+-------+---+-----+\n|Charlie| 35|   NY|\n|  Alice| 30|   CA|\n|  David| 40|   NY|\n|  Frank| 50|   TX|\n|    Bob| 45|   CA|\n|    Eve| 29|   TX|\n+-------+---+-----+\n\nOut[4]: [FileInfo(path='dbfs:/tmp/people_partitioned_by_state/_SUCCESS', name='_SUCCESS', size=0, modificationTime=1716000511000),\n FileInfo(path='dbfs:/tmp/people_partitioned_by_state/state=CA/', name='state=CA/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/tmp/people_partitioned_by_state/state=NY/', name='state=NY/', size=0, modificationTime=0),\n FileInfo(path='dbfs:/tmp/people_partitioned_by_state/state=TX/', name='state=TX/', size=0, modificationTime=0)]"
     ]
    }
   ],
   "source": [
    "# Read partitioned data\n",
    "partitioned_df = spark.read.option(\"header\", \"true\").csv(output_path)\n",
    "partitioned_df.show()\n",
    "\n",
    "# List the files in the output directory\n",
    "dbutils.fs.ls(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "31f6dbe6-f855-4591-a95b-fd04438efc1e",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "environmentMetadata": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Day-17 partitionBy()",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
